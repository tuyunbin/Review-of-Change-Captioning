# Review-of-Change-Captioning


## General Scenes: Video Surveillance, Natural Image (Birds), Synthetic Data, and Image Editing
### Awesome Works

- **Learning to Describe Differences Between Pairs of Similar Images** [[paper]](https://aclanthology.org/D18-1436.pdf) [[code and dataset]](https://github.com/harsh19/spot-the-diff)
  - Harsh Jhamtani, Taylor Berg-Kirkpatrick
  - EMNLP 2018
 
- **Robust Change Captioning** [[paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Park_Robust_Change_Captioning_ICCV_2019_paper.pdf) [[code and dataset]](https://github.com/Seth-Park/RobustChangeCaptioning)
  -  Dong Huk Park, Trevor Darrell, Anna Rohrbach
  - ICCV 2019

- **Expressing Visual Relationships via Language** [[paper]](https://aclanthology.org/P19-1182.pdf) [[code and dataset]](https://github.com/airsplay/VisualRelationships)
  -  Hao Tan, Franck Dernoncourt, Zhe Lin, Trung Bui, Mohit Bansal
  - ACL 2019
 
- **Neural Naturalist: Generating Fine-Grained Image Comparisons** [[paper]](https://aclanthology.org/D19-1065.pdf) [[dataset]](https://github.com/google-research-datasets/birds-to-words)
  -  Maxwell Forbes, Christine Kaeser-Chen, Piyush Sharma, Serge Belongie
  - EMNLP 2019
 
 
- **Finding It at Another Side: A Viewpoint-Adapted Matching Encoder for Change Captioning** [[paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590562.pdf)
  -  Xiangxi Shi, Xu Yang, Jiuxiang Gu, Sha q Joty, and Jianfei Cai
  - ECCV 2020
 
- **Image Change Captioning by Learning from an Auxiliary Task** [[paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Hosseinzadeh_Image_Change_Captioning_by_Learning_From_an_Auxiliary_Task_CVPR_2021_paper.pdf)
  -  Mehrdad Hosseinzadeh and Yang Wang
  - CVPR 2021

- **Viewpoint-Agnostic Change Captioning with Cycle Consistency** [[paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Viewpoint-Agnostic_Change_Captioning_With_Cycle_Consistency_ICCV_2021_paper.pdf) [[dataset]](https://github.com/hsgkim/clevr-dc)
  -  Hoeseong Kim, Jongseok Kim, Hyungseok Lee, Hyunsung Park, Gunhee Kim
  - ICCV 2021
 
- **Describing and Localizing Multiple Changes with Transformers** [[paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Qiu_Describing_and_Localizing_Multiple_Changes_With_Transformers_ICCV_2021_paper.pdf) [[code and dataset]](https://github.com/cvpaperchallenge/Describing-and-Localizing-Multiple-Change-with-Transformers)
  -  Yue Qiu, Shintaro Yamamoto, Kodai Nakashima, Ryota Suzuki, Kenji Iwata, Hirokatsu Kataoka, Yutaka Satoh
  - ICCV 2021
 
 
- **Scene Graph with 3D Information for Change Captioning** [[paper]](https://dl.acm.org/doi/abs/10.1145/3474085.3475712) 
  -  Zeming Liao, Qingbao Huang, Yu Liang, Mingyi Fu, Yi Cai, Qing Li
  - ACM MM 2021
 
 
- **Semantic Relation-aware Difference Representation Learning for Change Captioning** [[paper]](https://aclanthology.org/2021.findings-acl.6.pdf) [[code]](https://github.com/tuyunbin/SRDRL) 
  -  Yunbin Tu, Tingting Yao, Liang Li, Jiedong Lou, Shengxiang Gao, Zhengtao Yu, Chenggang Yan
  - ACL Fidings 2021

- **R<sup>3</sup>Net: Relation-embedded Representation Reconstruction Network for Change Captioning** [[paper]](https://aclanthology.org/2021.emnlp-main.735.pdf) [[code]](https://github.com/tuyunbin/R3Net)
  -  Yunbin Tu, Liang Li, Chenggang Yan, Shengxiang Gao, Zhengtao Yu
  - EMNLP 2021

- **L2C: Describing Visual Differences Needs Semantic Understanding of Individuals** [[paper]](https://aclanthology.org/2021.eacl-main.196.pdf) 
  -  An Yan, Xin Wang, Tsu-Jui Fu, William Yang Wang
  - EACL 2021
 
- **Image Difference Captioning with Instance-Level Fine-Grained Feature Representation** [[paper]](https://ieeexplore.ieee.org/document/9410374)  [[code]](https://github.com/VILAN-Lab/IFDC)
  -  Qingbao Huang, Yu Liang,  Jielong Wei, Yi Cai, Hanyu Liang, Ho-fung Leung, Qing Li
  - TMM 2022
 
- **Learning by Imagination: A Joint Framework for Text-Based Image Manipulation and Change Captioning** [[paper]](https://ieeexplore.ieee.org/document/9720958)  
  -  Kenan E. Ak, YingSun,  Joo Hwee Lim
  - TMM 2022

- **Image Difference Captioning with Pre-training and Contrastive Learning** [[paper]](https://cdn.aaai.org/ojs/20218/20218-13-24231-1-2-20220628.pdf)  [[code]](https://github.com/yaolinli/IDC)
  -  Linli Yao, Weiying Wang, Qin Jin
  - AAAI 2022

- **CLIP4IDC: CLIP for Image Difference Captioning** [[paper]](https://aclanthology.org/2022.aacl-short.5.pdf)  [[code]](https://github.com/sushizixin/CLIP4IDC)
  -  Zixin Guo, Tzu-Jui Julius Wang, Jorma Laaksonen
  - AACL 2022

- **I3N: Intra- and Inter-Representation Interaction Network for Change Captioning** [[paper]](https://ieeexplore.ieee.org/document/10050818) 
  -   Shengbin Yue, Yunbin Tu, LiangLi, Ying Yang, Shengxiang Gao, Zhengtao Yu
  - TMM 2023
  
- **Neighborhood Contrastive Transformer for Change Captioning** [[paper]](https://ieeexplore.ieee.org/document/10086696) [[code]](https://github.com/tuyunbin/NCT)
  -  Yunbin Tu, Liang Li, Li Su, Ke Lu, Qingming Huang
  - TMM 2023
 
- **Viewpoint-Adaptive Representation Disentanglement Network for Change Captioning** [[paper]](https://ieeexplore.ieee.org/document/10108947) [[code]](https://github.com/tuyunbin/VARD)
  -  Yunbin Tu, Liang Li, Li Su, Junping Du, Ke Lu, Qingming Huang
  - TIP 2023
 
- **Self-supervised Cross-view Representation Reconstruction for Change Captioning** [[paper]](https://openaccess.thecvf.com/content/ICCV2023/papers/Tu_Self-supervised_Cross-view_Representation_Reconstruction_for_Change_Captioning_ICCV_2023_paper.pdf) [[code]](https://github.com/tuyunbin/SCORER)
  -  Yunbin Tu, Liang Li, Li Su, Zheng-Jun Zha, Chenggang Yan, Qingming Huang
  - ICCV 2023

- **Semantic Object Alignment and Region-Aware Learning for Change Captioning** [[paper]](https://ieeexplore.ieee.org/document/10191266) 
  -   Weidong Tian, Quan Ren, Zhongqiu Zhao, and Ruihua Tian
  - IJCNN 2023
 
- **Graph Representation for Order-aware Visual Transformation** [[paper]](https://openaccess.thecvf.com/content/CVPR2023/papers/Qiu_Graph_Representation_for_Order-Aware_Visual_Transformation_CVPR_2023_paper.pdf) 
  -   Yue Qiu, Yanjun Sun, Fumiya Matsuzawa, Kenji Iwata, Hirokatsu Kataoka
  - CVPR 2023
 
- **Multi-Grained Representation Aggregating Transformer with Gating Cycle for Change Captioning** [[paper]](https://dl.acm.org/doi/10.1145/3660346) 
  -   Shengbin Yue, Yunbin Tu, LiangLi,  Shengxiang Gao, Zhengtao Yu
  - TOMM 2024

- **SMART: Syntax-calibrated Multi-Aspect Relation Transformer for Change Captioning** [[paper]](https://ieeexplore.ieee.org/abstract/document/10433795)  [[code]](https://github.com/tuyunbin/SMART)
  -   Yunbin Tu, Liang Li, Li Su, Zheng-Jun Zha, Qingming Huang
  - TPMAI 2024
 
  - **Context-aware Difference Distilling for Multi-change Captioning** [[paper]](https://aclanthology.org/2024.acl-long.430.pdf)  [[code]](https://github.com/tuyunbin/CARD)
  -   Yunbin Tu, Liang Li, Li Su, Zheng-Jun Zha, Qingming Huang
  - TPMAI 2024




    
## 3D Scenes
### Paper



## Remote sensing Scenes
### Paper
