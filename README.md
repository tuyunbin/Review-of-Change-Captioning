# Review-of-Change-Captioning


## General Scenes: Video Surveillance, Synthetic Data, and Image Editing
### Awesome Works

- **Learning to Describe Differences Between Pairs of Similar Images** [[paper]](https://aclanthology.org/D18-1436.pdf) [[code and dataset]](https://github.com/harsh19/spot-the-diff)
  - Harsh Jhamtani, Taylor Berg-Kirkpatrick
  - EMNLP 2018
 
- **Robust Change Captioning** [[paper]](https://openaccess.thecvf.com/content_ICCV_2019/papers/Park_Robust_Change_Captioning_ICCV_2019_paper.pdf) [[code and dataset]](https://github.com/Seth-Park/RobustChangeCaptioning)
  -  Dong Huk Park, Trevor Darrell, Anna Rohrbach
  - ICCV 2019

- **Expressing Visual Relationships via Language** [[paper]](https://aclanthology.org/P19-1182.pdf) [[code and dataset]](https://github.com/airsplay/VisualRelationships)
  -  Hao Tan, Franck Dernoncourt, Zhe Lin, Trung Bui, Mohit Bansal
  - ACL 2019
 
- **Neural Naturalist: Generating Fine-Grained Image Comparisons** [[paper]](https://aclanthology.org/D19-1065.pdf) [[dataset]](https://github.com/google-research-datasets/birds-to-words)
  -  Maxwell Forbes, Christine Kaeser-Chen, Piyush Sharma, Serge Belongie
  - EMNLP 2019
 
 
- **Finding It at Another Side: A Viewpoint-Adapted Matching Encoder for Change Captioning** [[paper]](https://www.ecva.net/papers/eccv_2020/papers_ECCV/papers/123590562.pdf)
  -  Xiangxi Shi, Xu Yang, Jiuxiang Gu, Sha q Joty, and Jianfei Cai
  - ECCV 2020
 
- **Image Change Captioning by Learning from an Auxiliary Task** [[paper]](https://openaccess.thecvf.com/content/CVPR2021/papers/Hosseinzadeh_Image_Change_Captioning_by_Learning_From_an_Auxiliary_Task_CVPR_2021_paper.pdf)
  -  Mehrdad Hosseinzadeh and Yang Wang
  - CVPR 2021

- **Viewpoint-Agnostic Change Captioning with Cycle Consistency** [[paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Kim_Viewpoint-Agnostic_Change_Captioning_With_Cycle_Consistency_ICCV_2021_paper.pdf) [[dataset]](https://github.com/hsgkim/clevr-dc)
  -  Hoeseong Kim, Jongseok Kim, Hyungseok Lee, Hyunsung Park, Gunhee Kim
  - ICCV 2021
 
- **Describing and Localizing Multiple Changes with Transformers** [[paper]](https://openaccess.thecvf.com/content/ICCV2021/papers/Qiu_Describing_and_Localizing_Multiple_Changes_With_Transformers_ICCV_2021_paper.pdf) [[code and dataset]](https://github.com/cvpaperchallenge/Describing-and-Localizing-Multiple-Change-with-Transformers)
  -  Yue Qiu, Shintaro Yamamoto, Kodai Nakashima, Ryota Suzuki, Kenji Iwata, Hirokatsu Kataoka, Yutaka Satoh
  - ICCV 2021
 
 
- **Scene Graph with 3D Information for Change Captioning** [[paper]](https://dl.acm.org/doi/abs/10.1145/3474085.3475712) 
  -  Zeming Liao, Qingbao Huang, Yu Liang, Mingyi Fu, Yi Cai, Qing Li
  - ACM MM 2021
 
 
- **Semantic Relation-aware Difference Representation Learning for Change Captioning** [[paper]](https://aclanthology.org/2021.findings-acl.6.pdf) [[code]](https://github.com/tuyunbin/SRDRL) 
  -  Yunbin Tu, Tingting Yao, Liang Li, Jiedong Lou, Shengxiang Gao, Zhengtao Yu, Chenggang Yan
  - ACL Fidings 2021

- **R<sup>3</sup>Net: Relation-embedded Representation Reconstruction Network for Change Captioning** [[paper]](https://aclanthology.org/2021.emnlp-main.735.pdf) [[code]](https://github.com/tuyunbin/R3Net)
  -  Yunbin Tu, Liang Li, Chenggang Yan, Shengxiang Gao, Zhengtao Yu
  - EMNLP 2021

- **L2C: Describing Visual Differences Needs Semantic Understanding of Individuals** [[paper]](https://aclanthology.org/2021.eacl-main.196.pdf) 
  -  An Yan, Xin Wang, Tsu-Jui Fu, William Yang Wang
  - EACL 2021
 
- **Image Difference Captioning with Instance-Level Fine-Grained Feature Representation** [[paper]](https://ieeexplore.ieee.org/document/9410374)  [[code]](https://github.com/VILAN-Lab/IFDC)
  -  Qingbao Huang, Yu Liang  Jielong Wei, Yi Cai, Hanyu Liang, Ho-fung Leung, Qing Li
  - TMM 2022


## 3D Scenes
### Paper



## Remote sensing Scenes
### Paper
